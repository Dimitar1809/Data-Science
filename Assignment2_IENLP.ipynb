{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5163acb3",
   "metadata": {},
   "source": [
    "Import the Standford NER tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "#try running the code wihtout it, if it doesnt work paste the directory of Java.exe\n",
    "os.environ['JAVAHOME'] =  \"C:/Program Files (x86)/Java/jre-1.8/bin/java.exe\"\n",
    "\n",
    "#change it based on where you have stored the Standford NER tagger\n",
    "jar_location = r'C:\\Users\\mitak\\OneDrive - University of Twente\\Documents\\UTwente\\DataScience\\IENLP\\stanford-ner-2020-11-17\\stanford-ner-4.2.0.jar'\n",
    "model_location_3classes = r'C:\\Users\\mitak\\OneDrive - University of Twente\\Documents\\UTwente\\DataScience\\IENLP\\stanford-ner-2020-11-17\\classifiers\\english.all.3class.distsim.crf.ser.gz'\n",
    "model_location_4classes = r'C:\\Users\\mitak\\OneDrive - University of Twente\\Documents\\UTwente\\DataScience\\IENLP\\stanford-ner-2020-11-17\\classifiers\\english.conll.4class.distsim.crf.ser.gz'\n",
    "model_location_7classes = r'C:\\Users\\mitak\\OneDrive - University of Twente\\Documents\\UTwente\\DataScience\\IENLP\\stanford-ner-2020-11-17\\classifiers\\english.muc.7class.distsim.crf.ser.gz'\n",
    "\n",
    "#implement the taggers\n",
    "st3 = StanfordNERTagger(model_location_3classes,jar_location,encoding='utf-8')\n",
    "st4 = StanfordNERTagger(model_location_4classes,jar_location,encoding='utf-8')\n",
    "st7 = StanfordNERTagger(model_location_7classes,jar_location,encoding='utf-8')\n",
    "\n",
    "#check if it is working\n",
    "print(st3)\n",
    "print(st4)\n",
    "print(st7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ab2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the Hamlet text\n",
    "Hamlet = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
    "print(Hamlet[:500])  # Print the first 500 characters as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77372264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the text\n",
    "tokenized_text = word_tokenize(Hamlet)\n",
    "\n",
    "#apply the different class taggers\n",
    "text_ner3 = st3.tag(tokenized_text)\n",
    "text_ner4 = st4.tag(tokenized_text)\n",
    "text_ner7 = st7.tag(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b955484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "309\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "#create a lists which will store the names\n",
    "combined_persons_3 = []\n",
    "combined_persons_4 = []\n",
    "combined_persons_7 = []\n",
    "\n",
    "#Exract the all the exapmples in PERSON class and also combine when the PERSON are next to each other(i.e. William and Shakespeare)\n",
    "for tag, chunk in groupby(text_ner3, key=lambda x: x[1]):\n",
    "    if tag == \"PERSON\":\n",
    "        # Extract and print the combined persons\n",
    "        combined_persons_3.append(' '.join(word for word, _ in chunk))\n",
    "        \n",
    "for tag, chunk in groupby(text_ner4, key=lambda x: x[1]):\n",
    "    if tag == \"PERSON\":\n",
    "        # Extract and print the combined persons\n",
    "        combined_persons_4.append(' '.join(word for word, _ in chunk))\n",
    "        \n",
    "for tag, chunk in groupby(text_ner7, key=lambda x: x[1]):\n",
    "    if tag == \"PERSON\":\n",
    "        # Extract and print the combined persons\n",
    "        combined_persons_7.append(' '.join(word for word, _ in chunk))\n",
    "        \n",
    "#since there are names that appear more than once store the names only once    \n",
    "combined_persons_3 = set(combined_persons)\n",
    "combined_persons_4 = set(combined_persons)\n",
    "combined_persons_7 = set(combined_persons)\n",
    "\n",
    "#print the length of lists for each class tagger\n",
    "print(len(combined_persons_3))\n",
    "print(len(combined_persons_4))\n",
    "print(len(combined_persons_7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
